{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\nhttps://cloud.google.com/use-cases/ocr?hl=en#ocr-optical-character-recognition-with-world-class-google-cloud-ai ","metadata":{}},{"cell_type":"code","source":"%%capture --no-stderr\n%pip install -U -q google-genai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T03:05:21.702384Z","iopub.execute_input":"2025-03-09T03:05:21.702753Z","iopub.status.idle":"2025-03-09T03:05:28.965553Z","shell.execute_reply.started":"2025-03-09T03:05:21.702726Z","shell.execute_reply":"2025-03-09T03:05:28.964066Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\nos.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-09T03:05:28.967533Z","iopub.execute_input":"2025-03-09T03:05:28.968021Z","iopub.status.idle":"2025-03-09T03:05:29.159765Z","shell.execute_reply.started":"2025-03-09T03:05:28.967968Z","shell.execute_reply":"2025-03-09T03:05:29.158159Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"https://ai.google.dev/gemini-api/docs/document-processing?lang=python","metadata":{}},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\nimport httpx\n\nclient = genai.Client()\n\ndoc_url = \"https://discovery.ucl.ac.uk/id/eprint/10089234/1/343019_3_art_0_py4t4l_convrt.pdf\"  # Replace with the actual URL of your PDF\n\n# Retrieve and encode the PDF byte\ndoc_data = httpx.get(doc_url).content\n\n# prompt = \"Summarize this document\"\n# prompt = \"Extract abstract of this document\"\nprompt = \"summarize the results in figure 1b\"\nresponse = client.models.generate_content(\n  model=\"gemini-1.5-flash\",\n  contents=[\n      types.Part.from_bytes(\n        data=doc_data,\n        mime_type='application/pdf',\n      ),\n      prompt])\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T03:07:02.090958Z","iopub.execute_input":"2025-03-09T03:07:02.091455Z","iopub.status.idle":"2025-03-09T03:07:24.175149Z","shell.execute_reply.started":"2025-03-09T03:07:02.091408Z","shell.execute_reply":"2025-03-09T03:07:24.173934Z"}},"outputs":[{"name":"stdout","text":"Figure 1b shows AlphaFold's TM-score compared to other groups for six new protein folds identified by CASP13 assessors.  AlphaFold achieves significantly higher TM-scores than other groups for each of these folds, demonstrating its ability to predict novel protein structures with high accuracy.  One fold (T1017s2-D1) is not shown due to unavailability for publication.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"prompt = \"print out the results of AlphaFold (or AF) in figure 1c as a table\"\nresponse = client.models.generate_content(\n  model=\"gemini-1.5-flash\",\n  contents=[\n      types.Part.from_bytes(\n        data=doc_data,\n        mime_type='application/pdf',\n      ),\n      prompt])\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T03:22:33.885418Z","iopub.execute_input":"2025-03-09T03:22:33.885785Z","iopub.status.idle":"2025-03-09T03:22:42.885080Z","shell.execute_reply.started":"2025-03-09T03:22:33.885754Z","shell.execute_reply":"2025-03-09T03:22:42.883985Z"}},"outputs":[{"name":"stdout","text":"Here's a table summarizing the contact precisions from Figure 1c of the AlphaFold paper:\n\n| Set       | FM (N=31) | FM/TBM (N=12) | TBM (N=61) |  AF 498 (032) | AF 498 (032) | AF 498 (032) |\n|-----------|------------|-----------------|-------------|----------------|----------------|----------------|\n|           | L long      | L/2 long        | L/5 long     | L long          | L/2 long        | L/5 long        |\n| **Contact precisions** |            |                 |             |                |                |                |\n| **AF**     | 45.5       | 42.9            | 39.8        | 58.0           | 55.1           | 51.7           |\n| **498**    | 59.1       | 53.0            | 48.9        | 74.2           | 64.5           | 64.2           |\n| **032**    | 68.3       | 65.5            | 61.9        | 82.4           | 80.3           | 76.4           |\n| **AF**     |            |                 |             | 90.6           | 90.5           | 87.1           |\n\n\n**Note:**  \"L\" refers to the length of the domain, and AF represents AlphaFold.  The numbers 498 and 032 refer to the two best-ranked contact prediction methods in CASP13.  The precisions show the percentage of correctly predicted contacts at varying distance ranges (L, L/2, and L/5).\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"### <font color='red'> Multiple PDFs </font>","metadata":{}},{"cell_type":"code","source":"from google import genai\nimport io\nimport httpx\n\nclient = genai.Client()\n\ndoc_url_1 = \"https://arxiv.org/pdf/2312.11805\" # Replace with the URL to your first PDF\ndoc_url_2 = \"https://arxiv.org/pdf/2403.05530\" # Replace with the URL to your second PDF\n\n# Retrieve and upload both PDFs using the File API\ndoc_data_1 = io.BytesIO(httpx.get(doc_url_1).content)\ndoc_data_2 = io.BytesIO(httpx.get(doc_url_2).content)\n\nsample_pdf_1 = client.files.upload(\n  file=doc_data_1,\n  config=dict(mime_type='application/pdf')\n)\nsample_pdf_2 = client.files.upload(\n  file=doc_data_2,\n  config=dict(mime_type='application/pdf')\n)\n\nprompt = \"What is the difference between each of the main benchmarks between these two papers? Output these in a table.\"\n\nresponse = client.models.generate_content(\n  model=\"gemini-1.5-flash\",\n  contents=[sample_pdf_1, sample_pdf_2, prompt])\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T03:19:58.351372Z","iopub.execute_input":"2025-03-09T03:19:58.351768Z","iopub.status.idle":"2025-03-09T03:20:36.865611Z","shell.execute_reply.started":"2025-03-09T03:19:58.351742Z","shell.execute_reply":"2025-03-09T03:20:36.864374Z"}},"outputs":[{"name":"stdout","text":"Here's a table summarizing the differences between the main benchmarks used in the two papers (Gemini 1.0 and Gemini 1.5).  Note that a complete comparison is difficult because the papers don't always use the same metrics and reporting methods and there is some overlap in benchmarks.\n\n| Benchmark Category | Gemini 1.0 Benchmarks | Gemini 1.5 Benchmarks | Key Differences |\n|---|---|---|---|\n| **Text-based Reasoning & Language Modeling** | MMLU, GSM8K, MATH, BIG-Bench-Hard, HellaSwag, DROP, HumanEval, Natural2Code | MMLU, GSM8K, MATH, BIG-Bench-Hard, HellaSwag, DROP, HumanEval, Natural2Code,  WMT23, MGSM,  Plus internal benchmarks  |  Gemini 1.5 adds WMT23 and MGSM for multilingual performance.  Internal benchmarks introduced, likely held out for more robust evaluation. MMLU, GSM8K etc. are updated versions with possibly different prompt engineering. |\n| **Image Understanding** | VQAv2, TextVQA, DocVQA, ChartQA, InfographicVQA, Ai2D, MathVista | VQAv2, TextVQA, DocVQA, ChartQA, InfographicVQA, Ai2D, MathVista, MMMU,  V*,  RealWorldQA, DUDE, TAT-DQA,  Plus internal benchmarks | Gemini 1.5 introduces several new benchmarks reflecting changes in the state of the art and focusing on multimodal reasoning, and hi-res images. Internal benchmarks added. |\n| **Video Understanding** | VATEX, ActivityNet-QA, YouCook2 | VATEX, ActivityNet-QA, YouCook2, EgoSchema, OpenEQA, 1H-VideoQA |  Gemini 1.5 introduces several new benchmarks emphasizing longer video lengths and more complex question answering.  |\n| **Audio Understanding** | FLEURS, Librispeech, VoxPopuli, COVOST2 | FLEURS, Librispeech, VoxPopuli, COVOST2, Plus internal benchmarks | Gemini 1.5 adds benchmarks to test the model's ability to transcribe and translate long audio inputs. Internal benchmarks added. |\n| **Long-Context Capabilities** |  Not explicitly evaluated in the same way. | Haystack (text, audio, video), MTOB, ASROB, Long Document QA,  In-Context Planning, Unstructured Multimodal Data Analytics | Gemini 1.5 heavily emphasizes and introduces novel metrics for evaluating long-context understanding across modalities. |\n\n\n**In short:** Gemini 1.5 significantly expands the scope and scale of its benchmarks, going beyond simply replicating existing benchmarks to evaluating novel capabilities related to long-context understanding and complex multimodal reasoning tasks.  The internal benchmarks are also expanded.\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}