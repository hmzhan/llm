{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U peft\n!pip install -U bitsandbytes\n!pip install -U accelerate\n!pip install -U \"transformers>=4.42.3\"","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:37:44.006849Z","iopub.execute_input":"2024-11-07T18:37:44.007205Z","iopub.status.idle":"2024-11-07T18:38:30.585925Z","shell.execute_reply.started":"2024-11-07T18:37:44.007169Z","shell.execute_reply":"2024-11-07T18:38:30.584906Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.13.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.46.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (1.1.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.44.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (1.1.1)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.25.1)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: transformers>=4.42.3 in /opt/conda/lib/python3.10/site-packages (4.46.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers>=4.42.3) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers>=4.42.3) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.42.3) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.42.3) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.42.3) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.42.3) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.42.3) (2024.8.30)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport copy\nimport torch\nimport numpy as np\nfrom datasets import Dataset\nfrom dataclasses import dataclass\nfrom sklearn.metrics import (\n    log_loss, \n    accuracy_score\n)\nfrom transformers import (\n    BitsAndBytesConfig,\n    Gemma2ForSequenceClassification,\n    GemmaTokenizerFast,\n    Gemma2Config,\n    PreTrainedTokenizerBase, \n    EvalPrediction,\n    Trainer,\n    TrainingArguments,\n    DataCollatorWithPadding,\n)\nfrom peft import (\n    LoraConfig, \n    get_peft_model, \n    prepare_model_for_kbit_training, \n    TaskType\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-07T18:38:30.587820Z","iopub.execute_input":"2024-11-07T18:38:30.588134Z","iopub.status.idle":"2024-11-07T18:38:50.779674Z","shell.execute_reply.started":"2024-11-07T18:38:30.588100Z","shell.execute_reply":"2024-11-07T18:38:50.778893Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"#### <font color='red'> dataclass </font>","metadata":{}},{"cell_type":"code","source":"@dataclass\nclass Config:\n    output_dir: str = \"output\"\n    model_ckpt: str = \"unsloth/gemma-2-9b-it-bnb-4bit\"  # 4-bit quantized gemma-2-9b-instruct\n    max_length: int = 1024\n    n_splits: int = 5\n    fold_idx: int = 0\n    optim_type: str = \"adamw_8bit\"\n    per_device_train_batch_size: int = 2\n    gradient_accumulation_steps: int = 2  # global batch size is 8 \n    per_device_eval_batch_size: int = 8\n    n_epochs: int = 1\n    freeze_layers: int = 16  # there're 42 layers in total, we don't add adapters to the first 16 layers\n    lr: float = 2e-4\n    warmup_steps: int = 20\n    lora_r: int = 16\n    lora_alpha: float = lora_r * 2\n    lora_dropout: float = 0.05\n    lora_bias: str = \"none\"\n    \nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:38:50.780919Z","iopub.execute_input":"2024-11-07T18:38:50.781511Z","iopub.status.idle":"2024-11-07T18:38:50.789478Z","shell.execute_reply.started":"2024-11-07T18:38:50.781476Z","shell.execute_reply":"2024-11-07T18:38:50.788458Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"config.lora_dropout","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:38:50.791321Z","iopub.execute_input":"2024-11-07T18:38:50.791601Z","iopub.status.idle":"2024-11-07T18:38:50.919985Z","shell.execute_reply.started":"2024-11-07T18:38:50.791570Z","shell.execute_reply":"2024-11-07T18:38:50.919049Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0.05"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"output\",\n    overwrite_output_dir=True,\n    report_to=\"none\",\n    num_train_epochs=config.n_epochs,\n    per_device_train_batch_size=config.per_device_train_batch_size,\n    gradient_accumulation_steps=config.gradient_accumulation_steps,\n    per_device_eval_batch_size=config.per_device_eval_batch_size,\n    logging_steps=10,\n    eval_strategy=\"epoch\",\n    save_strategy=\"steps\",\n    save_steps=200,\n    optim=config.optim_type,\n    fp16=True,\n    learning_rate=config.lr,\n    warmup_steps=config.warmup_steps,\n)\nlora_config = LoraConfig(\n    r=config.lora_r,\n    lora_alpha=config.lora_alpha,\n    # only target self-attention\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n    layers_to_transform=[i for i in range(42) if i >= config.freeze_layers],\n    lora_dropout=config.lora_dropout,\n    bias=config.lora_bias,\n    task_type=TaskType.SEQ_CLS,\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:39:55.952474Z","iopub.execute_input":"2024-11-07T18:39:55.952997Z","iopub.status.idle":"2024-11-07T18:39:55.982935Z","shell.execute_reply.started":"2024-11-07T18:39:55.952954Z","shell.execute_reply":"2024-11-07T18:39:55.982136Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"tokenizer = GemmaTokenizerFast.from_pretrained(config.model_ckpt)\ntokenizer.add_eos_token = True  # We'll add <eos> at the end\ntokenizer.padding_side = \"right\"","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:39:57.834302Z","iopub.execute_input":"2024-11-07T18:39:57.835177Z","iopub.status.idle":"2024-11-07T18:39:59.124988Z","shell.execute_reply.started":"2024-11-07T18:39:57.835135Z","shell.execute_reply":"2024-11-07T18:39:59.123966Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"model = Gemma2ForSequenceClassification.from_pretrained(\n    config.model_ckpt,\n    num_labels=3,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)\nmodel.config.use_cache = False\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, lora_config)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:40:13.372000Z","iopub.execute_input":"2024-11-07T18:40:13.372563Z","iopub.status.idle":"2024-11-07T18:42:45.597107Z","shell.execute_reply.started":"2024-11-07T18:40:13.372514Z","shell.execute_reply":"2024-11-07T18:42:45.596233Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3aae296a3d594a938089aad29087618a"}},"metadata":{}},{"name":"stderr","text":"Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/6.13G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d95e2efbf5a34341ad518469d06d3538"}},"metadata":{}},{"name":"stderr","text":"Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at unsloth/gemma-2-9b-it-bnb-4bit and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"model.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:43:24.725995Z","iopub.execute_input":"2024-11-07T18:43:24.726698Z","iopub.status.idle":"2024-11-07T18:43:24.738686Z","shell.execute_reply.started":"2024-11-07T18:43:24.726657Z","shell.execute_reply":"2024-11-07T18:43:24.737768Z"},"trusted":true},"outputs":[{"name":"stdout","text":"trainable params: 7,891,456 || all params: 9,249,608,192 || trainable%: 0.0853\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"ds = Dataset.from_csv(\"/kaggle/input/lmsys-chatbot-arena/train.csv\")\nds = ds.select(torch.arange(100))  # We only use the first 100 data for demo purpose","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:43:27.649424Z","iopub.execute_input":"2024-11-07T18:43:27.649819Z","iopub.status.idle":"2024-11-07T18:43:31.903942Z","shell.execute_reply.started":"2024-11-07T18:43:27.649780Z","shell.execute_reply":"2024-11-07T18:43:31.903112Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1db0321f9b6b4aad96a56aae738957d5"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"ds","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:43:34.126760Z","iopub.execute_input":"2024-11-07T18:43:34.127157Z","iopub.status.idle":"2024-11-07T18:43:34.133794Z","shell.execute_reply.started":"2024-11-07T18:43:34.127119Z","shell.execute_reply":"2024-11-07T18:43:34.132882Z"},"trusted":true},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie'],\n    num_rows: 100\n})"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"class CustomTokenizer:\n    def __init__(\n        self, \n        tokenizer: PreTrainedTokenizerBase, \n        max_length: int\n    ) -> None:\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        \n    def __call__(self, batch: dict) -> dict:\n        prompt = [\"<prompt>: \" + self.process_text(t) for t in batch[\"prompt\"]]\n        response_a = [\"\\n\\n<response_a>: \" + self.process_text(t) for t in batch[\"response_a\"]]\n        response_b = [\"\\n\\n<response_b>: \" + self.process_text(t) for t in batch[\"response_b\"]]\n        texts = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n        tokenized = self.tokenizer(texts, max_length=self.max_length, truncation=True)\n        labels=[]\n        for a_win, b_win in zip(batch[\"winner_model_a\"], batch[\"winner_model_b\"]):\n            if a_win:\n                label = 0\n            elif b_win:\n                label = 1\n            else:\n                label = 2\n            labels.append(label)\n        return {**tokenized, \"labels\": labels}\n        \n    @staticmethod\n    def process_text(text: str) -> str:\n        return \" \".join(eval(text, {\"null\": \"\"}))","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:43:37.220221Z","iopub.execute_input":"2024-11-07T18:43:37.220878Z","iopub.status.idle":"2024-11-07T18:43:37.230423Z","shell.execute_reply.started":"2024-11-07T18:43:37.220837Z","shell.execute_reply":"2024-11-07T18:43:37.229515Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"encode = CustomTokenizer(tokenizer, max_length=config.max_length)\nds = ds.map(encode, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:43:39.357420Z","iopub.execute_input":"2024-11-07T18:43:39.357820Z","iopub.status.idle":"2024-11-07T18:43:39.966402Z","shell.execute_reply.started":"2024-11-07T18:43:39.357780Z","shell.execute_reply":"2024-11-07T18:43:39.965499Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa8b3e04df2c4a1dbf4f37664a9935e9"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"def compute_metrics(eval_preds: EvalPrediction) -> dict:\n    preds = eval_preds.predictions\n    labels = eval_preds.label_ids\n    probs = torch.from_numpy(preds).float().softmax(-1).numpy()\n    loss = log_loss(y_true=labels, y_pred=probs)\n    acc = accuracy_score(y_true=labels, y_pred=preds.argmax(-1))\n    return {\"acc\": acc, \"log_loss\": loss}","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:43:48.506768Z","iopub.execute_input":"2024-11-07T18:43:48.507167Z","iopub.status.idle":"2024-11-07T18:43:48.515012Z","shell.execute_reply.started":"2024-11-07T18:43:48.507129Z","shell.execute_reply":"2024-11-07T18:43:48.514200Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"folds = [\n    (\n        [i for i in range(len(ds)) if i % config.n_splits != fold_idx],\n        [i for i in range(len(ds)) if i % config.n_splits == fold_idx]\n    ) \n    for fold_idx in range(config.n_splits)\n]","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:43:50.355767Z","iopub.execute_input":"2024-11-07T18:43:50.356156Z","iopub.status.idle":"2024-11-07T18:43:50.361909Z","shell.execute_reply.started":"2024-11-07T18:43:50.356117Z","shell.execute_reply":"2024-11-07T18:43:50.360808Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"train_idx, eval_idx = folds[config.fold_idx]\n\ntrainer = Trainer(\n    args=training_args, \n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=ds.select(train_idx),\n    eval_dataset=ds.select(eval_idx),\n    compute_metrics=compute_metrics,\n    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:43:55.480124Z","iopub.execute_input":"2024-11-07T18:43:55.480494Z","iopub.status.idle":"2024-11-07T18:52:52.682835Z","shell.execute_reply.started":"2024-11-07T18:43:55.480459Z","shell.execute_reply":"2024-11-07T18:52:52.681900Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2739703425.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [20/20 08:23, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Acc</th>\n      <th>Log Loss</th>\n      <th>Runtime</th>\n      <th>Samples Per Second</th>\n      <th>Steps Per Second</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.643000</td>\n      <td>1.294489</td>\n      <td>0.400000</td>\n      <td>1.294497</td>\n      <td>52.130200</td>\n      <td>0.384000</td>\n      <td>0.058000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=20, training_loss=2.047834014892578, metrics={'train_runtime': 536.2519, 'train_samples_per_second': 0.149, 'train_steps_per_second': 0.037, 'total_flos': 2853279087925248.0, 'train_loss': 2.047834014892578, 'epoch': 1.0})"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}