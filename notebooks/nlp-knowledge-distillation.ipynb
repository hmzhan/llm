{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### <font color='red'> DEPENDENCIES </font>","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\ngithub_token = user_secrets.get_secret(\"github_token\")\nhf_token = user_secrets.get_secret(\"hf_token\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:33:41.948433Z","iopub.execute_input":"2024-10-28T17:33:41.948968Z","iopub.status.idle":"2024-10-28T17:33:42.379754Z","shell.execute_reply.started":"2024-10-28T17:33:41.948845Z","shell.execute_reply":"2024-10-28T17:33:42.378421Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"repo = \"llm\"\nclone_url = f\"https://hmzhan:{github_token}@github.com/hmzhan/{repo}.git\"\nget_ipython().system(f\"git clone {clone_url}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:33:42.382178Z","iopub.execute_input":"2024-10-28T17:33:42.382688Z","iopub.status.idle":"2024-10-28T17:33:44.345494Z","shell.execute_reply.started":"2024-10-28T17:33:42.382632Z","shell.execute_reply":"2024-10-28T17:33:44.343797Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'llm'...\nremote: Enumerating objects: 170, done.\u001b[K\nremote: Counting objects: 100% (170/170), done.\u001b[K\nremote: Compressing objects: 100% (133/133), done.\u001b[K\nremote: Total 170 (delta 50), reused 133 (delta 31), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (170/170), 193.01 KiB | 6.43 MiB/s, done.\nResolving deltas: 100% (50/50), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(hf_token)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:33:44.349144Z","iopub.execute_input":"2024-10-28T17:33:44.349713Z","iopub.status.idle":"2024-10-28T17:33:45.062887Z","shell.execute_reply.started":"2024-10-28T17:33:44.349651Z","shell.execute_reply":"2024-10-28T17:33:45.061534Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/working/llm\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:33:45.065291Z","iopub.execute_input":"2024-10-28T17:33:45.065691Z","iopub.status.idle":"2024-10-28T17:33:45.072259Z","shell.execute_reply.started":"2024-10-28T17:33:45.065648Z","shell.execute_reply":"2024-10-28T17:33:45.070331Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### <font color='red'> MODEL </font>","metadata":{}},{"cell_type":"code","source":"from src.efficient_llm.model import pipe","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:34:41.990592Z","iopub.execute_input":"2024-10-28T17:34:41.991388Z","iopub.status.idle":"2024-10-28T17:34:41.997314Z","shell.execute_reply.started":"2024-10-28T17:34:41.991339Z","shell.execute_reply":"2024-10-28T17:34:41.995799Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### <font color='red'> DATA </font>","metadata":{}},{"cell_type":"code","source":"from src.efficient_llm.data import clinc","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:34:46.169496Z","iopub.execute_input":"2024-10-28T17:34:46.170721Z","iopub.status.idle":"2024-10-28T17:34:46.177153Z","shell.execute_reply.started":"2024-10-28T17:34:46.170648Z","shell.execute_reply":"2024-10-28T17:34:46.175284Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### <font color='red'> MODEL PERFORMANCE </font>","metadata":{}},{"cell_type":"code","source":"from src.efficient_llm.constants import MODEL_CKPT\nfrom src.efficient_llm.model_performance import PerformanceBenchmark\n\npb = PerformanceBenchmark(pipe, clinc[\"test\"])\nperf_metrics = pb.run_benchmark()\nprint(perf_metrics)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:35:02.627378Z","iopub.execute_input":"2024-10-28T17:35:02.627870Z","iopub.status.idle":"2024-10-28T17:40:37.788042Z","shell.execute_reply.started":"2024-10-28T17:35:02.627824Z","shell.execute_reply":"2024-10-28T17:40:37.786603Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/kaggle/working/llm/src/efficient_llm/model_performance.py:8: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n  accuracy_score = load_metric(\"accuracy\", trust_remote_code=True)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c98a7a44efad40719ec9686cb3226dd1"}},"metadata":{}},{"name":"stdout","text":"Model size (MB) - 418.15\nAverage latency (ms) - 62.75 +\\- 8.64\nAccuracy on test set - 0.867\n{'BERT baseline': {'size_mb': 418.147, 'time_avg_ms': 62.747, 'time_std_ms': 8.639, 'accuracy': 0.867}}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### <font color='red'> KNOWLEDGE DISTILLATION </font>","metadata":{}},{"cell_type":"code","source":"from src.efficient_llm.knowledge_distillation import knowledge_distillation\n\ndistillbert_trainer = knowledge_distillation()\ndistillbert_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T17:41:48.708321Z","iopub.execute_input":"2024-10-28T17:41:48.709123Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6a547499ea54129a33809d5d6c88f17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"288999b2fa0b404aa5c2e43010931c2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00fcc3eb41ff44a98d4cd0f91330a139"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ffba12a92374b26a9c6e6be4740fc30"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/15250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5534dce1ca7d4a3997572c816f952eb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c307c2b06373404bb96b90d16591f5b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dd249f0af13439b952c4bf233716cac"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3525f2437781490ca904e879a3a685ab"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   8/3180 00:26 < 3:55:24, 0.22 it/s, Epoch 0.02/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"pipe = pipeline(\"text-classification\", model=\"zhan/distillbert-base-uncased-finetuned-clinc\")\n\noptim_type = \"Distillation\"\npb = PerformanceBenchmark(pipe, clinc[\"test\"], optim_type=optim_type)\nperf_metrics.update(pb.run_benchmark())  # d.update(d2) this is a useful function\nprint(perf_metrics)\nplot_metrics(perf_metrics, optim_type)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T03:05:56.185013Z","iopub.execute_input":"2024-10-27T03:05:56.186145Z","iopub.status.idle":"2024-10-27T03:08:56.459547Z","shell.execute_reply.started":"2024-10-27T03:05:56.186075Z","shell.execute_reply":"2024-10-27T03:08:56.458359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color='red'> Optimal Hyperparameters: Optuna </font>\nNo enough space to implement Optuna","metadata":{}},{"cell_type":"code","source":"def hp_space(trial):\n    return {\n        'num_train_epochs': trial.suggest_int('num_train_epochs', 8, 10),\n        'alpha': trial.suggest_float('alpha', 0, 0.2),\n        'temperature': trial.suggest_int('temperature', 5, 10)\n    }\n\nbest_run = distillbert_trainer.hyperparameter_search(\n    n_trials=20, direction='maximize', hp_space=hp_space)\nprint(best_run)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T18:27:17.876810Z","iopub.execute_input":"2024-09-13T18:27:17.877077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='red'> DYNAMIC QUANTIZATION </font>","metadata":{}},{"cell_type":"code","source":"from llm.src.efficient_llm.constants import NEW_MODEL_CKPT\nfrom llm.src.efficient_llm.quantization import quantization_model\n\npipe = quantization_model(model_ckpt=NEW_MODEL_CKPT)\noptim_type = \"Distillation + Quantization\"\npb = PerformanceBenchmark(pipe, clinc[\"test\"], optim_type=optim_type)\nperf_metrics.update(pb.run_benchmark())\nprint(perf_metrics)\nplot_metrics(perf_metrics, optim_type)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T12:32:47.481510Z","iopub.execute_input":"2024-10-28T12:32:47.481978Z","iopub.status.idle":"2024-10-28T12:32:47.488782Z","shell.execute_reply.started":"2024-10-28T12:32:47.481933Z","shell.execute_reply":"2024-10-28T12:32:47.487308Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### <font color='red'> ONNX and ONNX Runtime </font>","metadata":{}},{"cell_type":"code","source":"!pip install onnxruntime","metadata":{"execution":{"iopub.status.busy":"2024-10-27T03:12:45.708570Z","iopub.execute_input":"2024-10-27T03:12:45.709508Z","iopub.status.idle":"2024-10-27T03:13:02.248834Z","shell.execute_reply.started":"2024-10-27T03:12:45.709463Z","shell.execute_reply":"2024-10-27T03:13:02.247740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from llm.src.efficient_llm.onnx import convert_model_onnx\nfrom llm.src.efficient_llm.constants import NEW_MODEL_CKPT, ONNX_MODEL_PATH\n\nconvert_model_onnx(NEW_MODEL_CKPT, ONNX_MODEL_PATH)\nonnx_model = create_model_for_provider(onnx_model_path)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T03:12:34.508827Z","iopub.execute_input":"2024-10-27T03:12:34.509526Z","iopub.status.idle":"2024-10-27T03:12:37.429464Z","shell.execute_reply.started":"2024-10-27T03:12:34.509484Z","shell.execute_reply":"2024-10-27T03:12:37.428387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe = OnnxPipeline(onnx_model, tokenizer)\npipe(query)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T03:14:42.917906Z","iopub.execute_input":"2024-10-27T03:14:42.918305Z","iopub.status.idle":"2024-10-27T03:14:42.960627Z","shell.execute_reply.started":"2024-10-27T03:14:42.918267Z","shell.execute_reply":"2024-10-27T03:14:42.959710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optim_type = \"Distillation + ORT\"\npb = OnnxPerformanceBenchmark(pipe, clinc[\"test\"], optim_type=optim_type, model_path=\"onnx/model.onnx\")\nperf_metrics.update(pb.run_benchmark())\nperf_metrics","metadata":{"execution":{"iopub.status.busy":"2024-10-27T03:14:50.037196Z","iopub.execute_input":"2024-10-27T03:14:50.038069Z","iopub.status.idle":"2024-10-27T03:16:55.280618Z","shell.execute_reply.started":"2024-10-27T03:14:50.038017Z","shell.execute_reply":"2024-10-27T03:16:55.279548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_metrics(perf_metrics, optim_type)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T03:17:06.873438Z","iopub.execute_input":"2024-10-27T03:17:06.874399Z","iopub.status.idle":"2024-10-27T03:17:07.325058Z","shell.execute_reply.started":"2024-10-27T03:17:06.874346Z","shell.execute_reply":"2024-10-27T03:17:07.323789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='red'> ONNX runtime + QUANTIZATION </font>","metadata":{}},{"cell_type":"code","source":"from onnxruntime.quantization import quantize_dynamic, QuantType\n\nmodel_input = \"onnx/model.onnx\"\nmodel_output = \"onnx/model.quant.onnx\"\nquantize_dynamic(model_input, model_output, weight_type=QuantType.QInt8)\nonnx_quantized_model = create_model_for_provider(model_input)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T03:17:23.176271Z","iopub.execute_input":"2024-10-27T03:17:23.176723Z","iopub.status.idle":"2024-10-27T03:17:27.002349Z","shell.execute_reply.started":"2024-10-27T03:17:23.176652Z","shell.execute_reply":"2024-10-27T03:17:27.001265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optim_type = \"Distillation + ORT + Quantization\"\npipe = OnnxPipeline(onnx_quantized_model, tokenizer)\npb = OnnxPerformanceBenchmark(pipe, clinc[\"test\"], optim_type=optim_type, model_path=model_output)\nperf_metrics.update(pb.run_benchmark())\nperf_metrics","metadata":{"execution":{"iopub.status.busy":"2024-10-27T03:17:32.139426Z","iopub.execute_input":"2024-10-27T03:17:32.139845Z","iopub.status.idle":"2024-10-27T03:19:39.017649Z","shell.execute_reply.started":"2024-10-27T03:17:32.139799Z","shell.execute_reply":"2024-10-27T03:19:39.016609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_metrics(perf_metrics, optim_type)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T03:20:56.740511Z","iopub.execute_input":"2024-10-27T03:20:56.740938Z","iopub.status.idle":"2024-10-27T03:20:57.175763Z","shell.execute_reply.started":"2024-10-27T03:20:56.740902Z","shell.execute_reply":"2024-10-27T03:20:57.174629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}